{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Collecting torch\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch\n",
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./openended/lib/python3.10/site-packages (4.20.1)\n",
      "Requirement already satisfied: requests in ./openended/lib/python3.10/site-packages (from transformers) (2.28.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./openended/lib/python3.10/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./openended/lib/python3.10/site-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./openended/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in ./openended/lib/python3.10/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in ./openended/lib/python3.10/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./openended/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./openended/lib/python3.10/site-packages (from transformers) (1.23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in ./openended/lib/python3.10/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./openended/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./openended/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./openended/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./openended/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./openended/lib/python3.10/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./openended/lib/python3.10/site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "# Install transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies from transformers\n",
    "from transformers import PegasusForConditionalGeneration, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Perform Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "I was too scared to tell a girl I liked her because I assumed all girls are straight.\n",
    " Such people don't have to think about that because anyone they talk to will most likely prefer the opposite gender.\n",
    "Online dating is a blessing for LGBTQ people because we can meet people more safely without having to go anywhere and know they are also in the community. \n",
    "And that is how I met Gauri. After two years of dating and travelling places, were moved in together, and two years later, I decided to propose to her.\n",
    " Gauri said 'YES'. Our families were surprised at first, but they knew Gauri as a friend and her parents knew me as well, which made things easier. Gauri's parents, however, took a couple of days to process it. My mom and dad still loved me and said they would never disown me, but they were a bit nervous about what society would think.\n",
    " However, they realised during the wedding planning that none of the desi aunties or uncles had any issues attending a lesbian wedding, so my parents also came around to being supportive.\n",
    " Now Gauri's parents treat me like a daughter, and my parents also love her.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens - number representation of our text\n",
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[11994,   117,   142, 15186,   281,   121,  3393,   956,   121, 14621,\n",
       "          3661,  1261,   107,  3096,   354,  4679, 18390,   929, 39331,   122,\n",
       "           203,   207,   113,  1225, 58339,   107,  3096,  1261, 38059,   130,\n",
       "           210,   130,   203,  2951,   121,  8321,  1014,  2560,   112,   225,\n",
       "         19003,  1094,   786,   108,  8789,   929,   118,   360,   111,   423,\n",
       "           121,  5129,   844,   107,  4101,  4311,  1100, 11994,   117, 22717,\n",
       "           121,  7155,   252,   111,  9041,   121, 83800,   107,   168,  3000,\n",
       "          1079,  3661, 50877,   108,   330,  7314,   143, 24899,   108, 22000,\n",
       "           312,  2951,   121,  8321,   111,  3819,  3661,   107,   168,   117,\n",
       "           432,  2540,   130,   114,   198, 18077,   144, 32300,   953,   194,\n",
       "          1261,   640,   112,   203,  2250,   971,  2400,   107,  4101, 10822,\n",
       "          1100, 58937,  4406,  7366,  3707,  1219,   375,   124, 11994,   115,\n",
       "           109,  1095,  5940,   116,   108,   130,   114, 15749,   112,   109,\n",
       "          8172,  3661,  1261,   108,   111,   211,  1291,   126,   115, 12086,\n",
       "           130, 11994, 21544,   107, 24613,  4101,  6695,  1100, 11994,  4586,\n",
       "           140,  1291,   115,  3555,   111,  2454,   177,   556,   108,   253,\n",
       "           130,   467, 17673,   116,   111,   114,  9041,   949,   327,   303,\n",
       "          2334,  8742,   107, 11994,  9179,   140,  1291,   115,  3390,   111,\n",
       "           140,   114,   698, 11827,   113,   109,  1261,   120,   117,   146,\n",
       "          1127, 17868,   121, 37804,   107, 11994,   280,   140, 17921,   122,\n",
       "           824, 21672,   107,  4876,   115, 12573,  4101,  9773,  1100, 11994,\n",
       "          4409,  7329,   130,   156,   113,   109,   205,   785,  3661,  4482,\n",
       "           107,  4101, 12365, 32887,  7393, 32887,  9368, 32887, 13185,  1100,\n",
       "             1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input tokens\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize \n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 11994,   117,   114,  3661,  1261,  1184,   141, 58937,  4406,\n",
       "         7366,  3707,   107,     1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output summary tokens\n",
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> I first met Gauri on an online dating site.</s>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode summary\n",
    "tokenizer.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing data set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a66bbde727ba1e1f41d31b41b4d7a900d40deb0d88520013182e6fd5e95c6d14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
